{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pl6pizPQaDcT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# بارگذاری دیتاست\n",
        "dataset = PygNodePropPredDataset(name='ogbn-products')\n",
        "data = dataset[0]\n",
        "\n",
        "print(f\"تعداد نودها: {data.num_nodes}\")\n",
        "print(f\"تعداد یالها: {data.num_edges}\")\n",
        "print(f\"تعداد ویژگی‌های هر نود: {data.num_node_features}\")\n",
        "print(f\"تعداد کلاس‌ها: {dataset.num_classes}\")\n",
        "\n",
        "# تقسیم داده به train/val/test\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train']\n",
        "val_idx = split_idx['valid']\n",
        "test_idx = split_idx['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Se8Qe9EXaLMy"
      },
      "outputs": [],
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_WfDIldaNmE"
      },
      "outputs": [],
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oiRzjR-azFi"
      },
      "source": [
        "# Train for Node Pr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmsiw1aEaThr"
      },
      "outputs": [],
      "source": [
        "def train(model, data, train_idx, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    out = model(data.x, data.edge_index)[train_idx]\n",
        "    loss = criterion(out, data.y[train_idx].view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, data, idx):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)[idx]\n",
        "        pred = out.argmax(dim=1)\n",
        "        true = data.y[idx].view(-1)\n",
        "\n",
        "        acc = accuracy_score(true.cpu(), pred.cpu())\n",
        "        f1 = f1_score(true.cpu(), pred.cpu(), average='weighted')\n",
        "\n",
        "    return acc, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8vKt6YYaWK4"
      },
      "outputs": [],
      "source": [
        "# پارامترها\n",
        "in_channels = data.num_node_features\n",
        "hidden_channels = 256\n",
        "out_channels = dataset.num_classes\n",
        "epochs = 100\n",
        "lr = 0.01\n",
        "\n",
        "# مدل، optimizer و loss function\n",
        "sage_model = GraphSAGE(in_channels, hidden_channels, out_channels)\n",
        "optimizer = torch.optim.Adam(sage_model.parameters(), lr=lr)\n",
        "criterion = torch.nn.NLLLoss()\n",
        "\n",
        "# آموزش\n",
        "sage_train_loss = []\n",
        "sage_val_acc = []\n",
        "sage_val_f1 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss = train(sage_model, data, train_idx, optimizer, criterion)\n",
        "    acc, f1 = evaluate(sage_model, data, val_idx)\n",
        "\n",
        "    sage_train_loss.append(loss)\n",
        "    sage_val_acc.append(acc)\n",
        "    sage_val_f1.append(f1)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Val Acc: {acc:.4f}, Val F1: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL7leoA0aa5Q"
      },
      "outputs": [],
      "source": [
        "gcn_model = GCN(in_channels, hidden_channels, out_channels)\n",
        "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=lr)\n",
        "\n",
        "gcn_train_loss = []\n",
        "gcn_val_acc = []\n",
        "gcn_val_f1 = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    loss = train(gcn_model, data, train_idx, optimizer, criterion)\n",
        "    acc, f1 = evaluate(gcn_model, data, val_idx)\n",
        "\n",
        "    gcn_train_loss.append(loss)\n",
        "    gcn_val_acc.append(acc)\n",
        "    gcn_val_f1.append(f1)\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Val Acc: {acc:.4f}, Val F1: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeQivnZVaf8_"
      },
      "outputs": [],
      "source": [
        "# ارزیابی روی داده تست\n",
        "sage_test_acc, sage_test_f1 = evaluate(sage_model, data, test_idx)\n",
        "gcn_test_acc, gcn_test_f1 = evaluate(gcn_model, data, test_idx)\n",
        "\n",
        "print(f'GraphSAGE - Test Accuracy: {sage_test_acc:.4f}, Test F1: {sage_test_f1:.4f}')\n",
        "print(f'GCN - Test Accuracy: {gcn_test_acc:.4f}, Test F1: {gcn_test_f1:.4f}')\n",
        "\n",
        "# رسم نمودارها\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(sage_train_loss, label='GraphSAGE')\n",
        "plt.plot(gcn_train_loss, label='GCN')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(sage_val_acc, label='GraphSAGE Val Acc')\n",
        "plt.plot(gcn_val_acc, label='GCN Val Acc')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuTpIVJJavYp"
      },
      "source": [
        "# Edge Pr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8hs4xDtatwO"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import LinkPrediction\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "class EdgePredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * in_channels, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        x = torch.cat([z[src], z[dst]], dim=1)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        return torch.sigmoid(self.lin2(x)).view(-1)\n",
        "\n",
        "# استفاده از embeddings یادگرفته شده توسط GraphSAGE\n",
        "edge_model = EdgePredictor(hidden_channels)\n",
        "optimizer = torch.optim.Adam(edge_model.parameters(), lr=0.01)\n",
        "\n",
        "# آموزش edge prediction\n",
        "for epoch in range(50):\n",
        "    edge_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # تولید embeddings با GraphSAGE\n",
        "    z = sage_model.conv1(data.x, data.edge_index)\n",
        "    z = sage_model.conv2(z, data.edge_index)\n",
        "\n",
        "    # نمونه‌گیری از یالهای مثبت و منفی\n",
        "    pos_edge_index = data.edge_index\n",
        "    neg_edge_index = negative_sampling(data.edge_index, num_nodes=data.num_nodes)\n",
        "\n",
        "    # محاسبه loss\n",
        "    pos_pred = edge_model(z, pos_edge_index)\n",
        "    neg_pred = edge_model(z, neg_edge_index)\n",
        "\n",
        "    pos_loss = -torch.log(pos_pred + 1e-15).mean()\n",
        "    neg_loss = -torch.log(1 - neg_pred + 1e-15).mean()\n",
        "    loss = pos_loss + neg_loss\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hc8Zf6tcI86"
      },
      "source": [
        "-----------------------------\n",
        "# Temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب numpy سازگار\n",
        "!pip install numpy==1.24.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "7dRLBy1Z64nB",
        "outputId": "2b989271-d643-4ae1-b77c-4e1d2c5b609e",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "bae4cc0d67604ccfbe353383e4fb1c07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نصب نسخه سازگار PyTorch\n",
        "!pip install torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# نصب کتابخانه‌های وابسته دقیقاً مطابق PyG توصیه‌شده برای torch==2.0.1\n",
        "!pip install pyg-lib==0.2.0 torch-scatter==2.1.1 torch-sparse==0.6.17 torch-cluster==1.6.1 torch-spline-conv==1.2.2 -f https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
        "\n",
        "# نصب نسخه صحیح PyG\n",
        "!pip install torch-geometric==2.3.1\n",
        "\n",
        "# نصب OGB\n",
        "!pip install ogb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSuy5VjbgKNV",
        "outputId": "8362e625-3778-4198-d1aa-9f25e680c570",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmake (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.24.4)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m122.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m118.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m118.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.18.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m117.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.17.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.32.3)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m119.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.0%2Bcu118-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is still looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.3.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.2.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89991 sha256=79f5107f7c52ca8a3a1e795c296ef88b5b0b9f1b2064e24172f378b6059f567e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, cmake, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cpu\n",
            "    Uninstalling torch-2.6.0+cpu:\n",
            "      Successfully uninstalled torch-2.6.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cpu\n",
            "    Uninstalling torchvision-0.21.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.21.0+cpu\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cpu\n",
            "    Uninstalling torchaudio-2.6.0+cpu:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cpu\n",
            "Successfully installed cmake-3.25.0 lit-15.0.7 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu118.html\n",
            "Collecting pyg-lib==0.2.0\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.2.0%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter==2.1.1\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.1%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse==0.6.17\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.17%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster==1.6.1\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.1%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv==1.2.2\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp311-cp311-linux_x86_64.whl (886 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.5/886.5 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse==0.6.17) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse==0.6.17) (1.24.4)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, pyg-lib, torch-sparse, torch-cluster\n",
            "Successfully installed pyg-lib-0.2.0+pt20cu118 torch-cluster-1.6.1+pt20cu118 torch-scatter-2.1.1+pt20cu118 torch-sparse-0.6.17+pt20cu118 torch-spline-conv-1.2.2+pt20cu118\n",
            "Collecting torch-geometric==2.3.1\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (1.24.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.3.1) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.3.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.3.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.3.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.3.1) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.3.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.3.1) (3.6.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910496 sha256=29ed1b2293f502709b98b79cdbe68f4a83a146e39a487ce03441984687daa2e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/78/6c/9fd091ca1c5e137c66cbd03696ffa14f75e9abc5abfe0dbcc6\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.1\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.24.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.4.0)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "# بارگذاری دیتاست ogbn-products\n",
        "dataset = PygNodePropPredDataset(name='ogbn-products')\n",
        "data = dataset[0]  # فقط یک شیء Data برمی‌گرداند\n",
        "\n",
        "# یال‌ها را بدون جهت می‌کنیم\n",
        "data.edge_index = to_undirected(data.edge_index)\n",
        "\n",
        "# تبدیل برچسب‌ها به [num_nodes]\n",
        "data.y = data.y.squeeze()\n",
        "\n",
        "# ماسک‌های آموزش، اعتبارسنجی، آزمون\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_idx = split_idx['train']\n",
        "val_idx = split_idx['valid']\n",
        "test_idx = split_idx['test']\n",
        "\n",
        "# بررسی اولیه\n",
        "print(data)\n",
        "print(f\"# Train samples: {train_idx.shape[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtZDu6LLxbsx",
        "outputId": "d7aa5ecf-327d-4745-a6e0-ba0e37673897"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(num_nodes=2449029, edge_index=[2, 123718152], x=[2449029, 100], y=[2449029])\n",
            "# Train samples: 196615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### سریع ساز:"
      ],
      "metadata": {
        "id": "Dpnp7UMqVkQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch import tensor\n",
        "\n",
        "# data = dataset[0]\n",
        "# data.edge_index = to_undirected(data.edge_index)\n",
        "# data.y = data.y.squeeze()\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# # فقط همین بخش روی GPU یا CPU منتقل میشه\n",
        "# data = data.to(device)\n",
        "\n",
        "train_idx = split_idx['train'].clone().detach()\n",
        "val_idx = split_idx['valid'].clone().detach()\n",
        "test_idx = split_idx['test'].clone().detach()\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=train_idx,\n",
        "    num_neighbors=[5, 3],\n",
        "    batch_size=256,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=val_idx,\n",
        "    num_neighbors=[5, 3],\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "test_loader = NeighborLoader(\n",
        "    data,\n",
        "    input_nodes=test_idx,\n",
        "    num_neighbors=[5, 3],\n",
        "    batch_size=256\n",
        ")\n"
      ],
      "metadata": {
        "id": "o0GDZfFqRtEO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GCN"
      ],
      "metadata": {
        "id": "_BNOvm_tEXG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# تعریف مدل GCN دو لایه\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features, hidden_channels, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        # لایه اول: از ویژگی‌ها به فضای پنهان\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels, bias=False)\n",
        "        # لایه دوم: از فضای پنهان به کلاس‌ها\n",
        "        self.conv2 = GCNConv(hidden_channels, num_classes, bias=True)\n",
        "\n",
        "    # def forward(self, data):\n",
        "    #     x, edge_index = data.x, data.edge_index\n",
        "    #     x = self.conv1(x, edge_index)\n",
        "    #     x = F.relu(x)\n",
        "    #     x = F.dropout(x, p=0.5, training=self.training)\n",
        "    #     x = self.conv2(x, edge_index)\n",
        "    #     return x\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Dropout کمتر برای سرعت (و جلوگیری از افت یادگیری در دیتای زیاد)\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Bwoo2by8D7Fo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMQwc7qrFQ2z",
        "outputId": "305f96af-c4ef-4ef9-b470-b0af2d21d3d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# مقادیر از دیتاست\n",
        "num_features = data.num_node_features       # =100\n",
        "num_classes = int(data.y.max().item()) + 1  # =47\n",
        "hidden_channels = 32                       # قابل تنظیم\n",
        "\n",
        "#-----------------------------------------------------\n",
        "save_path = \"/content/drive/MyDrive/gcn_node_last.pt\"\n",
        "#-----------------------------------------------------\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# ساخت مدل\n",
        "model = GCN(num_features, hidden_channels, num_classes).to(device)\n",
        "data = data.to(device)\n",
        "train_idx = train_idx.to(device)\n",
        "val_idx = val_idx.to(device)\n",
        "test_idx = test_idx.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "#----------------------------------------------------- گوگل کولب\n",
        "start_epoch = 1\n",
        "try:\n",
        "    # اگر فایلی از قبل ذخیره شده بود، از ادامه اجرا کن\n",
        "    checkpoint = torch.load(\"gcn_node_last.pt\")\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"✅ ادامه آموزش از epoch {start_epoch}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"⏳ آموزش از اول شروع می‌شود\")\n",
        "\n",
        "#----------------------------------------------------- گوگل درایو\n",
        "\n",
        "start_epoch = 1\n",
        "import os\n",
        "if os.path.exists(save_path):\n",
        "    checkpoint = torch.load(save_path)\n",
        "    model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"✅ ادامه آموزش از epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"🟡 فایل مدل قبلی یافت نشد. آموزش از ابتدا آغاز می‌شود.\")\n",
        "#-----------------------------------------------------\n",
        "\n",
        "# def train():\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     out = model(data)\n",
        "#     loss = F.cross_entropy(out[train_idx], data.y[train_idx])\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = F.cross_entropy(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def test():\n",
        "#     model.eval()\n",
        "#     out = model(data)\n",
        "#     pred = out.argmax(dim=1)\n",
        "\n",
        "#     accs = []\n",
        "#     for idx in [train_idx, val_idx, test_idx]:\n",
        "#         correct = (pred[idx] == data.y[idx]).sum().item()\n",
        "#         acc = correct / idx.shape[0]\n",
        "#         accs.append(acc)\n",
        "#     return accs\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "        total += batch.y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "for epoch in range(1, 4):\n",
        "    loss = train()\n",
        "    train_acc = test(train_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, \"\n",
        "          f\"Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}\")\n",
        "    torch.save(model.state_dict(), f\"gcn_node_epoch_{epoch:03d}.pt\")\n",
        "    # ذخیره مدل هر epoch\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }, save_path)\n",
        "    print(f\"💾 مدل در Google Drive ذخیره شد: epoch {epoch}\")\n"
      ],
      "metadata": {
        "id": "NaaE9NsJ4j5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a59ca5-841f-4774-e31a-f19aede7d361"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ آموزش از اول شروع می‌شود\n",
            "🟡 فایل مدل قبلی یافت نشد. آموزش از ابتدا آغاز می‌شود.\n",
            "Epoch 001, Loss: 1.5398, Train: 0.6493, Val: 0.6508, Test: 0.5570\n",
            "💾 مدل در Google Drive ذخیره شد: epoch 1\n",
            "Epoch 002, Loss: 1.4452, Train: 0.6516, Val: 0.6542, Test: 0.5648\n",
            "💾 مدل در Google Drive ذخیره شد: epoch 2\n",
            "Epoch 003, Loss: 1.4368, Train: 0.6535, Val: 0.6548, Test: 0.5621\n",
            "💾 مدل در Google Drive ذخیره شد: epoch 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crach & no run"
      ],
      "metadata": {
        "id": "qtIkHvvT4kzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# مقادیر از دیتاست\n",
        "num_features = data.num_node_features       # =100\n",
        "num_classes = int(data.y.max().item()) + 1  # =47\n",
        "hidden_channels = 128                       # قابل تنظیم\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# ساخت مدل\n",
        "model = GCN(num_features, hidden_channels, num_classes).to(device)\n",
        "data = data.to(device)\n",
        "train_idx = train_idx.to(device)\n",
        "val_idx = val_idx.to(device)\n",
        "test_idx = test_idx.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "# def train():\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     out = model(data)\n",
        "#     loss = F.cross_entropy(out[train_idx], data.y[train_idx])\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        loss = F.cross_entropy(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "# @torch.no_grad()\n",
        "# def test():\n",
        "#     model.eval()\n",
        "#     out = model(data)\n",
        "#     pred = out.argmax(dim=1)\n",
        "\n",
        "#     accs = []\n",
        "#     for idx in [train_idx, val_idx, test_idx]:\n",
        "#         correct = (pred[idx] == data.y[idx]).sum().item()\n",
        "#         acc = correct / idx.shape[0]\n",
        "#         accs.append(acc)\n",
        "#     return accs\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        out = model(batch.x, batch.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "        total += batch.y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "for epoch in range(1, 31):  # فقط 30 دوره برای سرعت اولیه\n",
        "    loss = train()\n",
        "    train_acc = test(train_loader)\n",
        "    val_acc = test(val_loader)\n",
        "    test_acc = test(test_loader)\n",
        "    print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, \"\n",
        "          f\"Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaeHiK4nEe5i",
        "outputId": "cf10a058-c3e9-4ca5-e171-7a083a2e0590"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001, Loss: 1.4965, Train: 0.6650, Val: 0.6638, Test: 0.5794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GraphSAGE"
      ],
      "metadata": {
        "id": "zFBE7p6GNDoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YiaEf5ayIM2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "    # def forward(self, data):\n",
        "    #     x, edge_index = data.x, data.edge_index\n",
        "    #     x = self.conv1(x, edge_index)\n",
        "    #     x = F.relu(x)\n",
        "    #     x = F.dropout(x, p=0.5, training=self.training)\n",
        "    #     x = self.conv2(x, edge_index)\n",
        "    #     return x\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.3, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "PsCUf037NBsA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sage_ckpt_path = \"/content/drive/MyDrive/sage_node_last.pt\"\n",
        "\n",
        "sage_model = GraphSAGE(num_features, hidden_channels, num_classes).to(device)\n",
        "optimizer = torch.optim.Adam(sage_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "start_epoch = 1\n",
        "import os\n",
        "if os.path.exists(sage_ckpt_path):\n",
        "    checkpoint = torch.load(sage_ckpt_path)\n",
        "    sage_model.load_state_dict(checkpoint['model'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"✅ ادامه آموزش GraphSAGE از epoch {start_epoch}\")\n",
        "else:\n",
        "    print(\"🟡 آموزش GraphSAGE از ابتدا شروع می‌شود.\")\n",
        "\n",
        "\n",
        "def train_sage():\n",
        "    sage_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        batch = batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = sage_model(batch.x, batch.edge_index)\n",
        "        loss = F.cross_entropy(out, batch.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_sage(loader):\n",
        "    sage_model.eval()\n",
        "    correct = total = 0\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "        out = sage_model(batch.x, batch.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == batch.y).sum().item()\n",
        "        total += batch.y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "\n",
        "sage_train_acc_list = []\n",
        "sage_val_acc_list = []\n",
        "sage_test_acc_list = []\n",
        "\n",
        "for epoch in range(start_epoch, start_epoch + 3):  # اپوک قابل تنظیم\n",
        "    loss = train_sage()\n",
        "    train_acc = test_sage(train_loader)\n",
        "    val_acc = test_sage(val_loader)\n",
        "    test_acc = test_sage(test_loader)\n",
        "\n",
        "    print(f\"[GraphSAGE] Epoch {epoch:03d}, Loss: {loss:.4f}, \"\n",
        "          f\"Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}\")\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model': sage_model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }, sage_ckpt_path)\n",
        "    print(f\"💾 مدل GraphSAGE ذخیره شد: epoch {epoch}\")\n",
        "\n",
        "    torch.save(sage_model.state_dict(), f\"sage_node_epoch_{epoch:03d}.pt\")\n"
      ],
      "metadata": {
        "id": "WywYu6c7NIrw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "c3794643-2996-409e-8bf3-3a4e3e1fba5c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟡 آموزش GraphSAGE از ابتدا شروع می‌شود.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3221906968>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# اپوک قابل تنظیم\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-3221906968>\u001b[0m in \u001b[0;36mtest_sage\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0msage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/loader/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/loader/node_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNodeSamplerInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_per_worker\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Execute `filter_fn` in the worker process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNodeSamplerInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;31m# Edge-based sampling #####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mseed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;31m# TODO (matthias) `return_edge_id` if edge features present\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0;31m# TODO (matthias) Ideally, `seed` inherits dtype from `colptr`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 out = torch.ops.pyg.neighbor_sample(\n\u001b[0m\u001b[1;32m    283\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval"
      ],
      "metadata": {
        "id": "YBt5XEnkN6ge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Acc"
      ],
      "metadata": {
        "id": "-yX5L9uMO1z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_with_f1(model, data, train_idx, val_idx, test_idx):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1).cpu().numpy()\n",
        "    labels = data.y.cpu().numpy()\n",
        "\n",
        "    results = {}\n",
        "    for name, idx in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx]):\n",
        "        idx = idx.cpu().numpy()\n",
        "        acc = (pred[idx] == labels[idx]).sum() / len(idx)\n",
        "        f1 = f1_score(labels[idx], pred[idx], average='macro')\n",
        "        results[name] = {'accuracy': acc, 'f1_score': f1}\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "gvBy3WKWN5IC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F1-Score"
      ],
      "metadata": {
        "id": "uOFG8v-2O6bh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_with_f1(model, data, train_idx, val_idx, test_idx):\n",
        "    model.eval()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    pred = out.argmax(dim=1).cpu().numpy()\n",
        "    labels = data.y.cpu().numpy()\n",
        "\n",
        "    results = {}\n",
        "    for name, idx in zip(['train', 'val', 'test'], [train_idx, val_idx, test_idx]):\n",
        "        idx = idx.cpu().numpy()\n",
        "        acc = (pred[idx] == labels[idx]).sum() / len(idx)\n",
        "        f1 = f1_score(labels[idx], pred[idx], average='macro')\n",
        "        results[name] = {'accuracy': acc, 'f1_score': f1}\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "9VIejnnzO89O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcn_model = GCN(dataset.num_node_features, 64, dataset.num_classes).to(device)\n",
        "gcn_results = evaluate_node_classification(gcn_model, data, train_idx, val_idx, test_idx)\n",
        "print(\"✅ GCN Metrics:\", gcn_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "KOd62kezaimO",
        "outputId": "e06000b6-dd5c-496b-fbbb-d24014a7cd15"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate_node_classification' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2084589251>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgcn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgcn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_node_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcn_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ GCN Metrics:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate_node_classification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. ارزیابی نهایی\n",
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        train_acc = accuracy_score(data.y[data.train_mask].cpu(),\n",
        "                                 pred[data.train_mask].cpu())\n",
        "        val_acc = accuracy_score(data.y[data.val_mask].cpu(),\n",
        "                               pred[data.val_mask].cpu())\n",
        "        test_acc = accuracy_score(data.y[data.test_mask].cpu(),\n",
        "                                pred[data.test_mask].cpu())\n",
        "\n",
        "        test_f1 = f1_score(data.y[data.test_mask].cpu(),\n",
        "                         pred[data.test_mask].cpu(), average='weighted')\n",
        "\n",
        "        return train_acc, val_acc, test_acc, test_f1\n",
        "\n",
        "print(\"\\nارزیابی GraphSAGE:\")\n",
        "sage_train_acc, sage_val_acc, sage_test_acc, sage_test_f1 = evaluate_model(sage_model, data)\n",
        "print(f\"Train Acc: {sage_train_acc:.4f}, Val Acc: {sage_val_acc:.4f}, \"\n",
        "      f\"Test Acc: {sage_test_acc:.4f}, Test F1: {sage_test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nارزیابی GCN:\")\n",
        "gcn_train_acc, gcn_val_acc, gcn_test_acc, gcn_test_f1 = evaluate_model(gcn_model, data)\n",
        "print(f\"Train Acc: {gcn_train_acc:.4f}, Val Acc: {gcn_val_acc:.4f}, \"\n",
        "      f\"Test Acc: {gcn_test_acc:.4f}, Test F1: {gcn_test_f1:.4f}\")\n",
        "\n",
        "# 6. مقایسه مدل‌ها\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# نمودار خطا\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(sage_loss, label='GraphSAGE')\n",
        "plt.plot(gcn_loss, label='GCN')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# نمودار دقت اعتبارسنجی\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(sage_val_acc, label='GraphSAGE')\n",
        "plt.plot(gcn_val_acc, label='GCN')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# مقایسه F1\n",
        "plt.subplot(2, 2, 3)\n",
        "models = ['GraphSAGE', 'GCN']\n",
        "test_f1 = [sage_test_f1, gcn_test_f1]\n",
        "plt.bar(models, test_f1, color=['blue', 'orange'])\n",
        "plt.title('Test F1-Score Comparison')\n",
        "plt.ylabel('F1-Score')\n",
        "\n",
        "# مقایسه دقت تست\n",
        "plt.subplot(2, 2, 4)\n",
        "test_acc = [sage_test_acc, gcn_test_acc]\n",
        "plt.bar(models, test_acc, color=['blue', 'orange'])\n",
        "plt.title('Test Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results_comparison.png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "p-3w3T-ciwD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. پیاده‌سازی اضافی: Edge Prediction\n",
        "class EdgePredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(EdgePredictor, self).__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * in_channels, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        x = torch.cat([z[src], z[dst]], dim=1)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        return torch.sigmoid(self.lin2(x)).squeeze()\n",
        "\n",
        "def get_embeddings(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # استخراج embeddings از لایه اول\n",
        "        embeddings = model.conv1(data.x, data.edge_index)\n",
        "        embeddings = F.relu(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "print(\"\\nآموزش مدل Edge Prediction با GraphSAGE:\")\n",
        "sage_embeddings = get_embeddings(sage_model, data)\n",
        "edge_model = EdgePredictor(256).to(device)\n",
        "optimizer = torch.optim.Adam(edge_model.parameters(), lr=0.01)\n",
        "\n",
        "# نمونه‌گیری از یالهای منفی\n",
        "def negative_sampling(edge_index, num_nodes, num_neg_samples=None):\n",
        "    if num_neg_samples is None:\n",
        "        num_neg_samples = edge_index.size(1)\n",
        "\n",
        "    neg_edge_index = torch.randint(0, num_nodes, (2, num_neg_samples), device=device)\n",
        "    return neg_edge_index\n",
        "\n",
        "for epoch in range(50):\n",
        "    edge_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # پیش‌بینی برای یالهای مثبت\n",
        "    pos_pred = edge_model(sage_embeddings, data.edge_index)\n",
        "    pos_loss = F.binary_cross_entropy(pos_pred, torch.ones_like(pos_pred))\n",
        "\n",
        "    # نمونه‌گیری و پیش‌بینی برای یالهای منفی\n",
        "    neg_edge_index = negative_sampling(data.edge_index, data.num_nodes, num_neg_samples=data.edge_index.size(1))\n",
        "    neg_pred = edge_model(sage_embeddings, neg_edge_index)\n",
        "    neg_loss = F.binary_cross_entropy(neg_pred, torch.zeros_like(neg_pred))\n",
        "\n",
        "    loss = pos_loss + neg_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/50, Loss: {loss.item():.4f}')\n",
        "\n",
        "# ارزیابی Edge Prediction\n",
        "edge_model.eval()\n",
        "with torch.no_grad():\n",
        "    pos_pred = edge_model(sage_embeddings, data.edge_index)\n",
        "    neg_edge_index = negative_sampling(data.edge_index, data.num_nodes, num_neg_samples=100000)\n",
        "    neg_pred = edge_model(sage_embeddings, neg_edge_index)\n",
        "\n",
        "    # محاسبه دقت\n",
        "    pos_acc = (pos_pred > 0.5).float().mean()\n",
        "    neg_acc = (neg_pred < 0.5).float().mean()\n",
        "    overall_acc = (pos_acc * pos_pred.size(0) + neg_acc * neg_pred.size(0)) / (pos_pred.size(0) + neg_pred.size(0))\n",
        "\n",
        "    print(f\"\\nنتایج Edge Prediction:\")\n",
        "    print(f\"Positive Accuracy: {pos_acc.item():.4f}\")\n",
        "    print(f\"Negative Accuracy: {neg_acc.item():.4f}\")\n",
        "    print(f\"Overall Accuracy: {overall_acc.item():.4f}\")"
      ],
      "metadata": {
        "id": "Kp3-Z2c5i3gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra Point"
      ],
      "metadata": {
        "id": "-wjpHZLW5H1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y-gMnLWtP1VT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  GCN"
      ],
      "metadata": {
        "id": "f_2jxfprSFNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Import\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import to_undirected, train_test_split_edges, negative_sampling\n",
        "from torch_geometric.nn import GCNConv\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 3. Load and process dataset\n",
        "dataset = PygNodePropPredDataset(name='ogbn-products', root='/tmp/ogb')\n",
        "graph = dataset[0]\n",
        "edge_index = torch.tensor(graph[0]['edge_index'], dtype=torch.long)\n",
        "x = torch.tensor(graph[0]['node_feat'], dtype=torch.float)\n",
        "y = torch.tensor(graph[1], dtype=torch.long).squeeze()\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "data.edge_index = to_undirected(data.edge_index)\n",
        "data = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.2)\n",
        "\n",
        "# 4. GCN Encoder\n",
        "class GCNEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# 5. Decode (inner product)\n",
        "def decode(z, edge_index):\n",
        "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
        "\n",
        "# 6. Loss with negative sampling\n",
        "def compute_loss(z, pos_edge_index, num_nodes, batch_size=100000):\n",
        "    pos_score = decode(z, pos_edge_index)\n",
        "    pos_loss = -F.logsigmoid(pos_score).mean()\n",
        "\n",
        "    neg_score_sum = 0\n",
        "    neg_batches = (pos_edge_index.size(1) // batch_size) + 1\n",
        "\n",
        "    for _ in range(neg_batches):\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=pos_edge_index,\n",
        "            num_nodes=num_nodes,\n",
        "            num_neg_samples=min(batch_size, pos_edge_index.size(1)),\n",
        "        )\n",
        "        neg_score = decode(z, neg_edge_index)\n",
        "        neg_score_sum += -F.logsigmoid(-neg_score).mean()\n",
        "\n",
        "    return pos_loss + neg_score_sum / neg_batches\n",
        "\n",
        "# 7. Training setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCNEncoder(data.num_node_features, 64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "x = data.x.to(device)\n",
        "train_edge_index = data.train_pos_edge_index.to(device)\n",
        "\n",
        "# 8. Train loop + Save to Drive\n",
        "save_path = \"/content/drive/MyDrive/edge_gcn_epoch_{epoch:03d}.pt\"\n",
        "for epoch in range(1, 4):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x, train_edge_index)\n",
        "    loss = compute_loss(z, train_edge_index, x.size(0))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"[EdgePred] Epoch {epoch:02d} | Loss: {loss:.4f}\")\n",
        "    torch.save(model.state_dict(), save_path.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHiYmBKj5G46",
        "outputId": "1bdef21f-0cc8-475f-c3e3-91affac9c261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Evaluation\n",
        "@torch.no_grad()\n",
        "def evaluate_edge_prediction(model, x, edge_index, pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    z = model(x, edge_index)\n",
        "    pos_scores = torch.sigmoid(decode(z, pos_edge_index)).cpu().numpy()\n",
        "    neg_scores = torch.sigmoid(decode(z, neg_edge_index)).cpu().numpy()\n",
        "    y_true = np.hstack([np.ones(pos_scores.shape[0]), np.zeros(neg_scores.shape[0])])\n",
        "    y_scores = np.hstack([pos_scores, neg_scores])\n",
        "    auc = roc_auc_score(y_true, y_scores)\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    return auc, ap\n",
        "\n",
        "full_edge_index = data.edge_index.to(device)\n",
        "val_pos = data.val_pos_edge_index.to(device)\n",
        "val_neg = negative_sampling(full_edge_index, x.size(0), num_neg_samples=val_pos.size(1))\n",
        "\n",
        "test_pos = data.test_pos_edge_index.to(device)\n",
        "test_neg = negative_sampling(full_edge_index, x.size(0), num_neg_samples=test_pos.size(1))\n",
        "\n",
        "val_auc, val_ap = evaluate_edge_prediction(model, x, full_edge_index, val_pos, val_neg)\n",
        "test_auc, test_ap = evaluate_edge_prediction(model, x, full_edge_index, test_pos, test_neg)\n",
        "\n",
        "print(f\"Validation AUC: {val_auc:.4f}, AP: {val_ap:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}, AP: {test_ap:.4f}\")"
      ],
      "metadata": {
        "id": "0QgjFBAs6OcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAGE"
      ],
      "metadata": {
        "id": "GaoedU5eSJkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import to_undirected, train_test_split_edges, negative_sampling\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 1. Load dataset\n",
        "dataset = PygNodePropPredDataset(name='ogbn-products', root='/tmp/ogb')\n",
        "graph = dataset[0]\n",
        "edge_index = torch.tensor(graph[0]['edge_index'], dtype=torch.long)\n",
        "x = torch.tensor(graph[0]['node_feat'], dtype=torch.float)\n",
        "y = torch.tensor(graph[1], dtype=torch.long).squeeze()\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "data.edge_index = to_undirected(data.edge_index)\n",
        "data = train_test_split_edges(data, val_ratio=0.05, test_ratio=0.2)\n",
        "\n",
        "# 2. GraphSAGE Encoder\n",
        "class SAGEEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, 64)\n",
        "        self.conv2 = SAGEConv(64, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# 3. Decoder (inner product)\n",
        "def decode(z, edge_index):\n",
        "    return (z[edge_index[0]] * z[edge_index[1]]).sum(dim=1)\n",
        "\n",
        "# 4. Loss with negative sampling\n",
        "def compute_loss(z, pos_edge_index, num_nodes, batch_size=100000):\n",
        "    pos_score = decode(z, pos_edge_index)\n",
        "    pos_loss = -F.logsigmoid(pos_score).mean()\n",
        "\n",
        "    neg_score_sum = 0\n",
        "    neg_batches = (pos_edge_index.size(1) // batch_size) + 1\n",
        "\n",
        "    for _ in range(neg_batches):\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=pos_edge_index,\n",
        "            num_nodes=num_nodes,\n",
        "            num_neg_samples=min(batch_size, pos_edge_index.size(1)),\n",
        "        )\n",
        "        neg_score = decode(z, neg_edge_index)\n",
        "        neg_score_sum += -F.logsigmoid(-neg_score).mean()\n",
        "\n",
        "    return pos_loss + neg_score_sum / neg_batches\n",
        "\n",
        "# 5. Train setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = SAGEEncoder(data.num_node_features, 64).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "x = data.x.to(device)\n",
        "train_edge_index = data.train_pos_edge_index.to(device)\n",
        "save_path = \"/content/drive/MyDrive/edge_sage_epoch_{epoch:03d}.pt\"\n",
        "\n",
        "# 6. Train loop\n",
        "for epoch in range(1, 4):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    z = model(x, train_edge_index)\n",
        "    loss = compute_loss(z, train_edge_index, x.size(0))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"[EdgePred - SAGE] Epoch {epoch:02d} | Loss: {loss:.4f}\")\n",
        "    torch.save(model.state_dict(), save_path.format(epoch=epoch))\n"
      ],
      "metadata": {
        "id": "VRMdn5oRSILP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluation\n",
        "@torch.no_grad()\n",
        "def evaluate_edge_prediction(model, x, edge_index, pos_edge_index, neg_edge_index):\n",
        "    model.eval()\n",
        "    z = model(x, edge_index)\n",
        "    pos_scores = torch.sigmoid(decode(z, pos_edge_index)).cpu().numpy()\n",
        "    neg_scores = torch.sigmoid(decode(z, neg_edge_index)).cpu().numpy()\n",
        "    y_true = np.hstack([np.ones(pos_scores.shape[0]), np.zeros(neg_scores.shape[0])])\n",
        "    y_scores = np.hstack([pos_scores, neg_scores])\n",
        "    auc = roc_auc_score(y_true, y_scores)\n",
        "    ap = average_precision_score(y_true, y_scores)\n",
        "    return auc, ap\n",
        "\n",
        "full_edge_index = data.edge_index.to(device)\n",
        "val_pos = data.val_pos_edge_index.to(device)\n",
        "val_neg = negative_sampling(full_edge_index, x.size(0), num_neg_samples=val_pos.size(1))\n",
        "test_pos = data.test_pos_edge_index.to(device)\n",
        "test_neg = negative_sampling(full_edge_index, x.size(0), num_neg_samples=test_pos.size(1))\n",
        "\n",
        "val_auc, val_ap = evaluate_edge_prediction(model, x, full_edge_index, val_pos, val_neg)\n",
        "test_auc, test_ap = evaluate_edge_prediction(model, x, full_edge_index, test_pos, test_neg)\n",
        "\n",
        "print(f\"✅ Validation AUC: {val_auc:.4f}, AP: {val_ap:.4f}\")\n",
        "print(f\"✅ Test AUC: {test_auc:.4f}, AP: {test_ap:.4f}\")"
      ],
      "metadata": {
        "id": "K29hn4EESOSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##-----------------------------------------"
      ],
      "metadata": {
        "id": "r0BKLttPEgh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
        "!pip install ogb"
      ],
      "metadata": {
        "id": "G1LGi8v0-CyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZLUBMLbcE85",
        "outputId": "de1164fd-92f9-480a-a818-7e5595b0dbd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading necessary files...\n",
            "This might take a while.\n",
            "Processing graphs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving...\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from ogb.nodeproppred import NodePropPredDataset\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 1. آماده‌سازی داده‌ها\n",
        "dataset = NodePropPredDataset(name='ogbn-products')\n",
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "graph, labels = dataset[0]\n",
        "edge_index = torch.tensor(graph['edge_index'], dtype=torch.long)\n",
        "x = torch.tensor(graph['node_feat'], dtype=torch.float)\n",
        "y = torch.tensor(labels, dtype=torch.long).squeeze()\n",
        "\n",
        "# ایجاد ماسک‌های آموزشی، اعتبارسنجی و تست\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "\n",
        "data.train_mask[split_idx[\"train\"]] = True\n",
        "data.val_mask[split_idx[\"valid\"]] = True\n",
        "data.test_mask[split_idx[\"test\"]] = True\n",
        "\n",
        "# 2. تعریف مدل‌ها\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# 3. تنظیمات آموزش\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data = data.to(device)\n",
        "\n",
        "def train_model(model, data, epochs=100):\n",
        "    model = model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    train_losses, val_accs, val_f1s = [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(data)\n",
        "        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ارزیابی\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(data)\n",
        "            pred = out.argmax(dim=1)\n",
        "\n",
        "            # محاسبه دقت و F1 برای اعتبارسنجی\n",
        "            val_acc = accuracy_score(data.y[data.val_mask].cpu(),\n",
        "                                   pred[data.val_mask].cpu())\n",
        "            val_f1 = f1_score(data.y[data.val_mask].cpu(),\n",
        "                             pred[data.val_mask].cpu(), average='weighted')\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        val_accs.append(val_acc)\n",
        "        val_f1s.append(val_f1)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}, '\n",
        "                  f'Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}')\n",
        "\n",
        "    return model, train_losses, val_accs, val_f1s\n",
        "\n",
        "# 4. آموزش مدل‌ها\n",
        "print(\"\\nآموزش مدل GraphSAGE:\")\n",
        "sage_model, sage_loss, sage_val_acc, sage_val_f1 = train_model(\n",
        "    GraphSAGE(data.num_features, 256, dataset.num_classes),\n",
        "    data\n",
        ")\n",
        "\n",
        "print(\"\\nآموزش مدل GCN:\")\n",
        "gcn_model, gcn_loss, gcn_val_acc, gcn_val_f1 = train_model(\n",
        "    GCN(data.num_features, 256, dataset.num_classes),\n",
        "    data\n",
        ")\n",
        "\n",
        "# 5. ارزیابی نهایی\n",
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "\n",
        "        train_acc = accuracy_score(data.y[data.train_mask].cpu(),\n",
        "                                 pred[data.train_mask].cpu())\n",
        "        val_acc = accuracy_score(data.y[data.val_mask].cpu(),\n",
        "                               pred[data.val_mask].cpu())\n",
        "        test_acc = accuracy_score(data.y[data.test_mask].cpu(),\n",
        "                                pred[data.test_mask].cpu())\n",
        "\n",
        "        test_f1 = f1_score(data.y[data.test_mask].cpu(),\n",
        "                         pred[data.test_mask].cpu(), average='weighted')\n",
        "\n",
        "        return train_acc, val_acc, test_acc, test_f1\n",
        "\n",
        "print(\"\\nارزیابی GraphSAGE:\")\n",
        "sage_train_acc, sage_val_acc, sage_test_acc, sage_test_f1 = evaluate_model(sage_model, data)\n",
        "print(f\"Train Acc: {sage_train_acc:.4f}, Val Acc: {sage_val_acc:.4f}, \"\n",
        "      f\"Test Acc: {sage_test_acc:.4f}, Test F1: {sage_test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nارزیابی GCN:\")\n",
        "gcn_train_acc, gcn_val_acc, gcn_test_acc, gcn_test_f1 = evaluate_model(gcn_model, data)\n",
        "print(f\"Train Acc: {gcn_train_acc:.4f}, Val Acc: {gcn_val_acc:.4f}, \"\n",
        "      f\"Test Acc: {gcn_test_acc:.4f}, Test F1: {gcn_test_f1:.4f}\")\n",
        "\n",
        "# 6. مقایسه مدل‌ها\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# نمودار خطا\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(sage_loss, label='GraphSAGE')\n",
        "plt.plot(gcn_loss, label='GCN')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# نمودار دقت اعتبارسنجی\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(sage_val_acc, label='GraphSAGE')\n",
        "plt.plot(gcn_val_acc, label='GCN')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# مقایسه F1\n",
        "plt.subplot(2, 2, 3)\n",
        "models = ['GraphSAGE', 'GCN']\n",
        "test_f1 = [sage_test_f1, gcn_test_f1]\n",
        "plt.bar(models, test_f1, color=['blue', 'orange'])\n",
        "plt.title('Test F1-Score Comparison')\n",
        "plt.ylabel('F1-Score')\n",
        "\n",
        "# مقایسه دقت تست\n",
        "plt.subplot(2, 2, 4)\n",
        "test_acc = [sage_test_acc, gcn_test_acc]\n",
        "plt.bar(models, test_acc, color=['blue', 'orange'])\n",
        "plt.title('Test Accuracy Comparison')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('results_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "# 7. پیاده‌سازی اضافی: Edge Prediction\n",
        "class EdgePredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(EdgePredictor, self).__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * in_channels, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, z, edge_index):\n",
        "        src, dst = edge_index\n",
        "        x = torch.cat([z[src], z[dst]], dim=1)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        return torch.sigmoid(self.lin2(x)).squeeze()\n",
        "\n",
        "def get_embeddings(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # استخراج embeddings از لایه اول\n",
        "        embeddings = model.conv1(data.x, data.edge_index)\n",
        "        embeddings = F.relu(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "print(\"\\nآموزش مدل Edge Prediction با GraphSAGE:\")\n",
        "sage_embeddings = get_embeddings(sage_model, data)\n",
        "edge_model = EdgePredictor(256).to(device)\n",
        "optimizer = torch.optim.Adam(edge_model.parameters(), lr=0.01)\n",
        "\n",
        "# نمونه‌گیری از یالهای منفی\n",
        "def negative_sampling(edge_index, num_nodes, num_neg_samples=None):\n",
        "    if num_neg_samples is None:\n",
        "        num_neg_samples = edge_index.size(1)\n",
        "\n",
        "    neg_edge_index = torch.randint(0, num_nodes, (2, num_neg_samples), device=device)\n",
        "    return neg_edge_index\n",
        "\n",
        "for epoch in range(50):\n",
        "    edge_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # پیش‌بینی برای یالهای مثبت\n",
        "    pos_pred = edge_model(sage_embeddings, data.edge_index)\n",
        "    pos_loss = F.binary_cross_entropy(pos_pred, torch.ones_like(pos_pred))\n",
        "\n",
        "    # نمونه‌گیری و پیش‌بینی برای یالهای منفی\n",
        "    neg_edge_index = negative_sampling(data.edge_index, data.num_nodes, num_neg_samples=data.edge_index.size(1))\n",
        "    neg_pred = edge_model(sage_embeddings, neg_edge_index)\n",
        "    neg_loss = F.binary_cross_entropy(neg_pred, torch.zeros_like(neg_pred))\n",
        "\n",
        "    loss = pos_loss + neg_loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch+1}/50, Loss: {loss.item():.4f}')\n",
        "\n",
        "# ارزیابی Edge Prediction\n",
        "edge_model.eval()\n",
        "with torch.no_grad():\n",
        "    pos_pred = edge_model(sage_embeddings, data.edge_index)\n",
        "    neg_edge_index = negative_sampling(data.edge_index, data.num_nodes, num_neg_samples=100000)\n",
        "    neg_pred = edge_model(sage_embeddings, neg_edge_index)\n",
        "\n",
        "    # محاسبه دقت\n",
        "    pos_acc = (pos_pred > 0.5).float().mean()\n",
        "    neg_acc = (neg_pred < 0.5).float().mean()\n",
        "    overall_acc = (pos_acc * pos_pred.size(0) + neg_acc * neg_pred.size(0)) / (pos_pred.size(0) + neg_pred.size(0))\n",
        "\n",
        "    print(f\"\\nنتایج Edge Prediction:\")\n",
        "    print(f\"Positive Accuracy: {pos_acc.item():.4f}\")\n",
        "    print(f\"Negative Accuracy: {neg_acc.item():.4f}\")\n",
        "    print(f\"Overall Accuracy: {overall_acc.item():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}